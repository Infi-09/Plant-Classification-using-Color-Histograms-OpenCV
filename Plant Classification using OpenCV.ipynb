{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1bebfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7731e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB Histogram class\n",
    "class RGBHistogram:\n",
    "    def __init__(self, bins):\n",
    "        self.bins = bins\n",
    "        \n",
    "    def describe(self, image, mask=None):\n",
    "        hist = cv2.calcHist([image], [0, 1, 2], mask, self.bins, [0, 256, 0, 256, 0, 256])\n",
    "        cv2.normalize(hist, hist)\n",
    "        return hist.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176dadbb",
   "metadata": {},
   "source": [
    "The RGBHistogram class is used to encapsulate how the flower images are quantified. The\n",
    "__init__ method on Line 4 takes only a single argument a list containing the number of bins for the 3D histogram. Describing the image will be handled by the describe method , which takes two parameters, an image that the color histogram will be built from, and an optional mask. If we  upplies a mask, then only pixels associated with the masked region will be used in constructing the histogram. This allows him to describe only the petals of the image, ignoring the rest of the image (i.e., the background, which is irrelevant to the flower itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46563d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a custom mask folder for the flowers image\n",
    "for path in imagePaths:\n",
    "    image = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    canny = cv2.Canny(gray, 40, 160)\n",
    "    maskColor = cv2.applyColorMap(canny, cv2.COLORMAP_SPRING)\n",
    "    flowerName = str(path).split(\"/\")[-1]\n",
    "    cv2.imwrite(\"data/flowersColorMask/\"+flowerName, maskColor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47edd0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for the masked images we have created\n",
    "maskPaths = []\n",
    "\n",
    "for path in os.listdir(\"data/flowersColorMask\"):\n",
    "    maskPaths.append(\"data/flowersColorMask/\"+path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea6e0046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for the original images\n",
    "imagePaths = []\n",
    "\n",
    "for path in os.listdir(\"data/flowers\"):\n",
    "    imagePaths.append(\"data/flowers/\"+path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79b5a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List contains the features of the images\n",
    "data = []\n",
    "# List that contains the flowers names\n",
    "target = []\n",
    "\n",
    "# Object \n",
    "desc = RGBHistogram([8, 8, 8])\n",
    "\n",
    "for (imagePath, maskPath) in zip(imagePaths, maskPaths):\n",
    "    # Read the image\n",
    "    image = cv2.imread(imagePath)\n",
    "    # Read the mask\n",
    "    mask = cv2.imread(maskPath)\n",
    "    # Convert the BGR image to gray\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Extract the features from the masked image\n",
    "    features = desc.describe(image, mask)\n",
    "    \n",
    "    data.append(features)\n",
    "    target.append(imagePath.split(\"/\")[-1].split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19eee97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "bougainvillea       0.78      0.81      0.79        26\n",
      "      daisies       0.83      0.96      0.89        26\n",
      "       garden       0.48      0.46      0.47        24\n",
      "    gardenias       0.81      0.88      0.84        24\n",
      "     hibiscus       0.89      0.62      0.73        26\n",
      "   hydrangeas       0.79      0.94      0.86        16\n",
      "       lilies       0.60      0.79      0.68        19\n",
      "      orchids       0.73      0.55      0.63        20\n",
      "      peonies       0.41      0.65      0.50        17\n",
      "        tulip       0.80      0.36      0.50        22\n",
      "\n",
      "     accuracy                           0.70       220\n",
      "    macro avg       0.71      0.70      0.69       220\n",
      " weighted avg       0.72      0.70      0.69       220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unique labels for flowers\n",
    "labels = np.unique(target)\n",
    "# Calling the Label Encoder\n",
    "le = LabelEncoder()\n",
    "# Coverting flower names into their corresponding integers\n",
    "target = le.fit_transform(target)\n",
    "\n",
    "# Split the data\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(data, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=84)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_test, model.predict(X_test), target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24ab4299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Image Name:  gardenias\n",
      "Predicted Image Name:  GARDENIAS\n",
      "Actual Image Name:  tulip\n",
      "Predicted Image Name:  TULIP\n",
      "Actual Image Name:  tulip\n",
      "Predicted Image Name:  TULIP\n",
      "Actual Image Name:  bougainvillea\n",
      "Predicted Image Name:  BOUGAINVILLEA\n",
      "Actual Image Name:  lilies\n",
      "Predicted Image Name:  LILIES\n"
     ]
    }
   ],
   "source": [
    "# Randomly selecting five flower sample for the predictions\n",
    "for i in np.random.choice(np.arange(0, len(imagePaths)), 5):\n",
    "    \n",
    "    imagePath = imagePaths[i]\n",
    "    maskPath = maskPaths[i]\n",
    "    \n",
    "    image = cv2.imread(imagePath)\n",
    "    mask = cv2.imread(maskPath)\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    features = desc.describe(image, mask)\n",
    "    flower = le.inverse_transform(model.predict([features]))[0]\n",
    "    name = imagePath.split(\"/\")[-1].split(\"_\")[0]\n",
    "    print(\"Actual Image Name: \", name.upper())\n",
    "    print(\"Predicted Image Name: \", flower.upper())\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047cd677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
